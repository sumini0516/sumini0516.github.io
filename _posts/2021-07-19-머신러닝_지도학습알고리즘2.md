---
layout: article
title: "머신러닝-지도학습알고리즘2"
categories: [머신러닝, 기계학습, KNN]
tags: [머신러닝, 기계학습입문, KNN, 분류, 지도학습]
key: 머신러닝 포스팅
---
이번에는 일반화에 대해 알아보겠다.

모델이 처음 보는 데이터에 대해 정확하게 예측할 수 있으면 이를 훈련 세트에서 테스트 세트로 일반화**generalization**되었다고 한다. 일반화 성능이 최대가 되는 모델이 최적이다. 이때, 훈련 세트와 테스트 세트가 매우 비슷하다면 그 모델이 테스트 세트에서도 정확하게 예측하리라 기대할 수 있는데, 항상 그런 것은 아니다. 이를 과대적합 **overfitting**이라고 하는데, 가진 정보를 모두 사용해서 너무 복잡한 모델을 만들 경우에 발생한다. 과대적합이 발생하면, 학습 데이터에만 잘 맞고, 새로운 데이터에는 잘 맞지 않는다. 그렇다면, 간단한 모델을 만들면 어떻게 될까? 너무 간단한 모델을 만들면 데이터의 다양성과 면면을 잡아내지 못하고 훈련세트에도 잘 맞지 않는 문제가 발생한다. 이를 과소적합 **underfitting**이라고 한다.

따라서, 모델을 복잡하게 할수록 훈련 데이터에 대해서는 정확히 예측할 수 있지만 너무 복잡해지면 새로운 데이터에서는 잘 일반화되지 못한다. 우리가 찾아야 하는 모델은 일반화 성능이 최대가 되는 최적점에 있는 모델이다. 다음 그림을 보자.

<img width="384" alt="719-사진1" src="https://user-images.githubusercontent.com/72678812/126088523-86938d8d-f57a-4837-bcbb-ce29eeea045e.png">

그림에서 표시된 최적점이 우리가 찾아야 하는 모델이다.
